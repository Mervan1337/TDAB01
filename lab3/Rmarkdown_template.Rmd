---
title: "Lab 3"
author: "Mervan Palmér (merpa433)"
date: '2023-10-16'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

3.1.1

1) 
```{r}

    interval <- seq(-5, 15, 0.01)
    res <- dt(x = interval, df = 1)
    plot(interval, res, type="l")
```

2)
```{r}
    data <- c(11.3710, 9.4353, 10.3631, 10.6329, 10.4043, 9.8939, 11.5115)
    hist(data, xlim = c(-5, 15))
```

3)
```{r}
    normal_log_likelihood <- function(mu, data) {
        return((-length(data)/2) * log(2*pi) - (1/2) * sum((data - mu)^2))
    }
    llik <- normal_log_likelihood(5, data)
    print(round(llik, 1))

    log_like_hood <- c()
    for (mu in interval) {
        log_like <- c(log_like_hood, normal_log_likelihood(mu, data))
    }
    plot(interval, log_like_hood, type="l")
```

4)

Proof for proportional posterior for my
$$ p(\theta \mid y) \propto p(y \mid \theta) * p(\theta) $$

Because it is the my parameter we want, we changes the theta to my instead.

$$ p(\mu \mid y) \propto p(y \mid \mu) * p(\mu) $$

The likelihood function:

$$ p(y \mid \mu) =  (2\pi\sigma^2)^{\frac{-n}{2}} * \exp{(\frac{-1}{2\sigma^2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})} $$

Sigma^2 = 1 gives:

$$ p(y \mid \mu) =  (2\pi)^{\frac{-n}{2}} * \exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})} $$

We can shorten the terms that doesn't contain my.
$$ p(y \mid \mu) = \exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})} $$


Prior function:
$$ p(\mu) = \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{\mu^2}{\nu} \right)^{\!-\frac{\nu+1}{2}},\! $$

v = 1 gives:

$$ p(\mu) = \frac{\Gamma(1)} {\sqrt{\pi}\,\Gamma(\frac{1}{2})\,(1+\mu^2)}
             = \frac{1} {\sqrt{\pi}\,\Gamma(\frac{1}{2})\,(1+\mu^2)}
$$
Then the posterior will be:
$$
    p(\mu \mid y) = (\exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})})\,
    (\frac{1} {\sqrt{\pi}\,\Gamma(\frac{1}{2})\,(1+\mu^2)}) =
$$

$$
    = \frac{\exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})}} {\sqrt{\pi}\,\Gamma(\frac{1}{2})\,(1+\mu^2)}
    = \frac{1}{\sqrt{\pi}\,\Gamma(\frac{1}{2})} * \frac{\exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})}}{1 + \mu^2}
    = c * \frac{\exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})}}{1 + \mu^2}
$$

Since we want the proportienal posterior, we could shorten the constant c.
$$ p(\mu \mid y) = \frac{\exp{(\frac{-1}{2}\sum_{i=1}^{n}(y_{i} - \mu)^{2})}}{1 + \mu^2} $$

5)

```{r}
    posterior <- function(mu, data) {
        return(exp((-1/2)*sum((data - mu)^2)) / (1 + mu^2))
    }

    posterior_values_res <- c()
    for (mu in interval) {
        posterior_values <- c(posterior_values_res, posterior(mu, data))
    }
    plot(interval, posterior_values_res, type="l")

```

3.2.1

1)

Since we don't have any data: 

Proir for Pa: Beta (1, 1)

Proir for Pb: Beta (1, 1)

Eftersom de är samma så plottar vi bara ena
Since they are the same we only plot one of them. :)

```{r}
    alpha = 1
    beta = 1
    interval <- seq(0, 1, 0.01)
    prior_pa <- dbeta(x = interval, shape1 = alpha, shape2 = beta)
    plot(interval, prior_pa, type="l")
```
2)
Here is the expected value for beta.
$$ \mathbb{E}(x) = \frac{\alpha}{\alpha + \beta} $$

So for product A:

E(x) = (8+1) / (8+1 + 13-8+1) = 9 / 15 = 0.6

For product B:

E(x) = (2+1) / (2+1 + 3-2+1) = 3 / 5 = 0.6

We can see that the product has the same expected value based on the formula.

3)

```{r}
    n <- 100000
    pA <- rbeta(n = n, shape1 = 8+1, shape2 = 13-8+1)
    pB <- rbeta(n = n, shape1 = 2+1, shape2 = 3-2+1)
    Xa <- rbinom(n = n, size = 87, prob = pA)
    Xb <- rbinom(n = n, size = 87, prob = pB)

    hist(Xa)
    hist(Xb)
```


a)

```{r}
    print(sum(Xa > 40) / n)
    print(sum(Xb > 40) / n)
```

b)

```{r}
    print(mean(Xa))
    print(mean(Xb))
```











